# ! Some of the tools used by this pipeline have poor conda support and require manual creation of the environment
# ! with the exact name from the .yaml file. Snakemake will fail at runtime if the environment is not available!
# ! See workflow/envs/manual/ for the corresponding environment files

annot_gtf: /project/hfa_work/ENCODE/data/gencode_human/version_45/gencode.v45.annotation.gtf.gz
reference_fa: /project/hfa_work/ENCODE/data/gencode_human/version_45/GRCh38.p14.genome.fa

# * additional columns are allowed and ignored for all of these

# tsv file with "sample ID", "group" and "file", file can either be a .fastq.gz or a .bam file
# fastq: reads are mapped with minimap2
# bam: .bai file is created next to it, if it doesn't exist yet
sample_table: /project/hfa_work/ENCODE/ONT_TSS/sample_table.tsv
# tsv file with "sample ID" matching the IDs above and the path in the "file" column, use null if not available
rnaseq_fastq_fofn: null
# tsv file with "group" matching groups from above and "file" with the path to the bed.gz file
# samples from tissues without a matching CAGE file are ignored in the analysis
CAGE_table: /project/hfa_work/ENCODE/ONT_TSS/CAGE_table.tsv
# Download bed file from https://polyasite.unibas.ch/atlas#2
PolyASitePeaks: /project/hfa_work/ENCODE/data/PolyA_Site/atlas.clusters.2.0.GRCh38.96.bed.gz

flair:
  # FLAIRs memory consumption drastically increase for .bed files over 1GB
  # If the .bed file is larger than this, it will be split by chromosome
  # Using 1.05e9 and not just 1e9 because lung is just ever so slightly over 1GB
  bed_split_size: 1.05e9

# Specify a subset of the available tools (flair, isoquant, isotools, stringtie)
# * IsoTools is special here. It requires manual creation of the environment (see at the top), but it allows you to
# * pass any environment name, that starts with "isotools", allowing you to test multiple versions of IsoTools in parallel
tools: ["isotools_v0", "isotools_v2"]

isotools:
  query: "BALANCED"
  unify_ends: {}
  #   isotools_v4: False

stringtie:
  # Stringtie needs manual building with make, the path to the binary is needed
  path: /project/hfa_work/ENCODE/code/stringtie/stringtie

star:
  # Extra options for STAR
  index:
    extra: ""
  align:
    # Same options as SQANTI3 would use (very close to default ENCODE options)
    extra: "--alignSJoverhangMin 8 --alignSJDBoverhangMin 1 --outFilterType BySJout --outSAMunmapped Within --outFilterMultimapNmax 20 --outFilterMismatchNoverLmax 0.04 --outFilterMismatchNmax 999 --alignIntronMin 20 --alignIntronMax 1000000 --alignMatesGapMax 1000000 --sjdbScore 1 --twopassMode Basic"

sqanti:
  # Path to the SQANTI3 repo
  path: /project/hfa_work/ENCODE/code/SQANTI3
  # Download polyA motif list from SQANTI repo or link your own
  polyA_motif_list: "/project/hfa_work/ENCODE/code/SQANTI3/data/polyA_motifs/mouse_and_human.polyA_motif.txt"
  # see https://github.com/ConesaLab/SQANTI3/wiki/Running-SQANTI3-Quality-Control#arguments-and-parameters-in-sqanti3-qc for options
  extra: "--ratio_TSS_metric mean"
  plot_groups:
    all:
      tools: ["isotools_v0", "isotools_v2"]
      groups: all
    wtc11:
      tools: all
      tool_names: ["IsoTools v0", "IsoTools v2"]
      groups: ["CapTrap_ONT/wtc11","CapTrap_PacBio/wtc11","cDNA_ONT/wtc11","cDNA_PacBio/wtc11","dRNA_ONT/wtc11","R2C2_ONT/wtc11"]
      group_names: ["CapTrap_ONT","CapTrap_PacBio","cDNA_ONT","cDNA_PacBio","dRNA_ONT","R2C2_ONT"]
  # Whether to include titles in plots
  plot_titles: False

# cluster couldn't find conda
path_to_conda: /home/lankenau/miniforge-pypy3/bin

# Reduces bam files to chr15 for testing
test_run: False
# Replace resources from above, when test_run is set to True
test_config:
  sample_table: /project/hfa_work/ENCODE/data/reads/metadata_tissue_test.tsv
  CAGE_table: /project/hfa_work/ENCODE/data/CAGE_test
  rnaseq_fastq_fofn: /project/hfa_work/ENCODE/data/rna_seq/fastq_test/rnaseq_metadata_fastq_test.tsv
  annot_gtf: /project/hfa_work/ENCODE/data/gencode_human/version_46/gencode.v46.annotation.chr15.gtf.gz
